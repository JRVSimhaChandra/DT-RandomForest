{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa793ac-17ed-4734-a5d0-11d727880b01",
   "metadata": {},
   "source": [
    "# Business Case:- Based on given features we need to find whether an employee will leave the comoany or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0eaae28-40eb-42c8-9ee2-22c8a3bcac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sweetviz in c:\\users\\chand\\appdata\\roaming\\python\\python312\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from sweetviz) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sweetviz) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from sweetviz) (3.8.4)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sweetviz) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from sweetviz) (1.13.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from sweetviz) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in c:\\users\\chand\\appdata\\roaming\\python\\python312\\site-packages (from sweetviz) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.11.1->sweetviz) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.43.0->sweetviz) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->sweetviz) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "%matplotlib inline\n",
    "import sweetviz as sv\n",
    "!pip install sweetviz\n",
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d0d504-d98c-416e-abb3-cd1ee933d924",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HR-Employee-Attrition.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR-Employee-Attrition.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HR-Employee-Attrition.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cec5aa-1a2e-4314-b388-56964b06478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ef26f-a77c-44fc-9c11-e796340cd6ac",
   "metadata": {},
   "source": [
    "# Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402b41a-1edf-4bdf-aaf5-a6943aac6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f56ba-ba6a-4361-96d0-e1d59a1059a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b2e1b-c2fc-478d-a044-703d6d2d1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb79443-92fc-42c3-ba65-e31eeb3968a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(pd.set_option('display.max_columns',None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4207325-402b-4203-b5ea-99a5b26ca461",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9f5f1-6f23-4754-a487-d0b5390c90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=['O']) # It will give you info about categorical data/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c33ba-2f33-4337-b8cb-42db9a02b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580c8d0-43f9-4859-9764-101bed2dcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a9ed7-f18d-4594-a758-ffa5dacaf2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e626658-6bd9-4dac-aae3-24b1c005000d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d19869-2975-4a09-9b78-953d95db4ac1",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece138be-8ca4-42a0-bf5d-28c0303db92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "my_report = sv.analyze(data)\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6686a7-4ddb-4173-a6b1-b6f886df2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "# Assuming `data` is your DataFrame\n",
    "my_report = sv.analyze(data)\n",
    "\n",
    "# Display the report\n",
    "my_report.show_html('report.html')\n",
    "\n",
    "# To automatically open the report in your default web browser\n",
    "my_report.show_html('report.html', open_browser=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ccf5e-2675-45bd-8dbf-44a5b0e0ffe2",
   "metadata": {},
   "source": [
    "# Insights from univariant\n",
    "\n",
    "* People betwwen the age group 25-40 are the majority.\n",
    "* 70% of the people travel rarely, 20% travel frequently rest do not travel.\n",
    "* more than 70% of the employeres belong to research and development.\n",
    "* Almost 50% of the people are nearer to the office i.e the distance from their home is lesser than or equal to 10.\n",
    "* More than 60% of the people have educational qualification of 4 and 5.\n",
    "* Majority (40%) of the people are from life science field and 30% are from medical field.\n",
    "* 60% of the people are almost satisfied with environment condition of the office with more than 3 ratings.\n",
    "* Gender count:60% male 40% female.\n",
    "* 60% of the people have partial involment in job and 20% have good involvement.\n",
    "* More than 60% employees seem to be satisfied with their job.\n",
    "* 50% of the people are married , 30% single and rest are divorced.\n",
    "* 60% of the people have less thanm 10k income.\n",
    "* 40% of the people have worked for less than 1 company which implies they are freshers.\n",
    "* 30% of the people have worked for more than 5 companies.\n",
    "* 80% of the people have average work rating.\n",
    "* 60% of the people hav worked for the same company only for 5 years or lesser.\n",
    "* 80% of the people own only 1 or 0 stock at the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3022006-2444-4ae6-9067-c275b2b18e77",
   "metadata": {},
   "source": [
    "# Bivariate Analysis\n",
    "\n",
    "Checking relationship of all variables with respect to target variable\n",
    "\n",
    "Categorical Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df63a05-f47e-4347-926d-e4e09e0ac0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with categorical variables only\n",
    "data1=data[['Attrition',\n",
    "            'BusinessTravel',\n",
    "            'Department',\n",
    "            'EducationField',\n",
    "            'Gender',\n",
    "            'JobRole',\n",
    "            'MaritalStatus',\n",
    "            'Over18',\n",
    "            'OverTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbefb6f-5c47-44e5-bd20-a3027bc5bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 # new data from with categorical variables only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ffc50a-1f19-491e-98df-cc464e75b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over 18 is a constant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a96c0e-cf1f-4961-b0b2-f176c7dba912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting how every categorical feature correlate with the \"Target\"\n",
    "plt.figure(figsize=(50, 50), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data1:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.countplot(x=data1[column].dropna(axis=0)\n",
    "                          ,hue=data.Attrition)\n",
    "        plt.xlabel(column,fontsize=40)\n",
    "        plt.ylabel('Attrition',fontsize=40)\n",
    "        plt.xticks(fontsize=25, rotation=45)\n",
    "        plotnumber+=1\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638cf6a-2bee-405c-a2e0-d5584b3744fb",
   "metadata": {},
   "source": [
    "# Insights of Bivariant\n",
    "* These are the insights wrt attrition.\n",
    "* More male employees are expected to quit their job.\n",
    "* People who travel more are more expected to leave the job.\n",
    "* People who do not do overtime do not job leave the job.\n",
    "* Singles are expected to quit the job.\n",
    "* People from life science and medical field are more probably leaving their job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55910ca4-9589-45e1-9d0f-97d108f14747",
   "metadata": {},
   "source": [
    "# Discrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08eb7c9-a899-40a7-a20f-8d379bb4526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=data[['Education',\n",
    "            'EmployeeCount',\n",
    "            'EnvironmentSatisfaction',\n",
    "            'JobInvolvement',\n",
    "            'JobLevel',\n",
    "            'JobSatisfaction',\n",
    "            'NumCompaniesWorked',\n",
    "            'PerformanceRating',\n",
    "            'RelationshipSatisfaction',\n",
    "            'StandardHours',\n",
    "            'StockOptionLevel',\n",
    "            'TrainingTimesLastYear',\n",
    "            'WorkLifeBalance']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3741ae8-d336-4127-bcea-c3616d046260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting how every categorical feature correlate with the \"Target\"\n",
    "plt.figure(figsize=(20, 25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data3:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.countplot(x=data3[column].dropna(axis=0)\n",
    "                          ,hue=data.Attrition)\n",
    "        plt.xlabel(column,fontsize=40)\n",
    "        plt.ylabel('Attrition',fontsize=20)\n",
    "        plt.xticks(fontsize=25, rotation=25)\n",
    "        plotnumber+=1\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722e7e0-e061-4da5-91ff-4ce5ebbdb93f",
   "metadata": {},
   "source": [
    "# Bivariant analysis of continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53bf6e-6610-4341-bf0a-f55ad3097e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting how every categorical feature correlate with the \"Target\"\n",
    "plt.figure(figsize=(20, 25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data3:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.histplot(x=data3[column].dropna(axis=0)\n",
    "                          ,hue=data.Attrition)\n",
    "        plt.xlabel(column,fontsize=40)\n",
    "        plt.ylabel('Attrition',fontsize=20)\n",
    "        plt.xticks(fontsize=25, rotation=25)\n",
    "        plotnumber+=1\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de49161-ec31-4389-9e7f-cdaf2025563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting how every categorical feature correlate with the \"Target\"\n",
    "plt.figure(figsize=(20, 25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data3:\n",
    "    if plotnumber<=16 :\n",
    "        ax = plt.subplot(4,4,plotnumber)\n",
    "        sns.boxplot(x=data3[column].dropna(axis=0)\n",
    "                          ,hue=data.Attrition)\n",
    "        plt.xlabel(column,fontsize=40)\n",
    "        plt.ylabel('Attrition',fontsize=20)\n",
    "        plt.xticks(fontsize=25, rotation=25)\n",
    "        plotnumber+=1\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84f5a8-8f08-4b59-a567-32d4dfd50455",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attrition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae4964-3970-4173-b314-533bf646d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Attrition=data.Attrition.map({'Yes':1,'No':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7eea5-1174-4de2-a508-0f5005d3bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.BusinessTravel.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd29070-6931-41b7-99a7-2ba4854d4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.BusinessTravel=data.BusinessTravel.map({'Travel_Rarely':1, 'Travel_Frequently':2, 'Non-Travel':0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90812d7c-0e0b-445b-8ae7-21e6b863df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Department.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45842c8-ac46-4e49-a9d3-614e36bd07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Department=data.Department.map({'Sales':1, 'Research & Development':2, 'Human Resources':0})\n",
    "data.Department\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744349e-66ed-4d18-9a66-e8b1e8d86d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.EducationField.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89fd80-4ac4-4317-99f4-6e3ad7729164",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.EducationField=data.EducationField.map({'Life Sciences':1, 'Other':2, 'Medical':2, 'Marketing':2,\n",
    "       'Technical Degree':1, 'Human Resources':0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20570da-b092-4a99-9be1-2e9a0595a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18418ff1-bd68-4942-94a1-16553f90a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender=pd.get_dummies(data.Gender,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8a377-7e76-437a-bd58-80cd5bbf81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a282c4-926a-4387-8c8d-0ee7f383f99b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.JobRole.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659d753-8210-411e-b809-5bf63d632b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.JobRole=data.JobRole.map({'Sales Executive':1,'Research Scientist':2,'Laboratory Technician':1,'Manufacturing Director':2,'Healthcare Representative':1,'Manager':2,'Sales Representative':1,'Research Director':3,'Human Resources':0})\n",
    "data.JobRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd723809-b608-46fc-9dde-d89da2dcf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MaritalStatus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35d48e-d11b-4a30-9750-42d71aa31a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label = LabelEncoder()\n",
    "data.MaritalStatus=label.fit_transform(data.MaritalStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47313dee-efe5-4493-86f5-851303d7163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.OverTime=label.fit_transform(data.OverTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095545d8-5d06-48f0-b40a-f88337e130cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.OverTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e7948-0d99-4c25-89a8-2368ff4088d4",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90654ddd-2c68-48dd-9544-2be33dd7b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(data3.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fa849-eb63-4701-b153-3878fd9a569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StandardHours.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741f1e4-102d-4ef7-8160-c6d7f55318d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430a99d-5772-45f9-9316-f8da72963ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed0372-32d5-459c-b6cc-d2e138a1982a",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4b6f0-0b69-4e8e-9d5c-264eec81eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Attrition', axis=1)\n",
    "y = data.Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee22d5-1da5-47ca-8393-7663c957ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Attrition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6d6d7-7006-4602-a5e4-f85b21031b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ed1b5-7646-4962-9905-8a52cc1f3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm=SMOTE()\n",
    "print(Counter(y))\n",
    "x_sm,y_sm=sm.fit_resample(x,y)\n",
    "print(Counter(y_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24733437-3660-4567-8ad5-2035fa8ca8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e4b8d-f4d4-4b7a-99e8-fefe3fc2f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm=SMOTE()\n",
    "print(Counter(y_train))\n",
    "x_sm,y_sm=sm.fit_resample(x_train,y_train)\n",
    "print(Counter(y_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835c898-8f0e-4610-9494-5892a872470d",
   "metadata": {},
   "source": [
    "# Hyperparameters of DecisionTree\n",
    "\n",
    "* Hyperparameter tuning is searching the hyperparameter space for a set of values that will optimize your model architecture.\n",
    "\n",
    "* Criterion: The function to measure the quality of split. Supported criteria are \"Gini\" for the Gini impurity and \"Entropy\" for the information gain.\n",
    "\n",
    "* Splitter: This is how the decision tree searches the features for split. The default value is set to \"Best\". That is, for each node, the algorithm considers all  the features and choose the best split. If you decide to set the splitter parameter to \"Random\", then a random subset of features will be considered.\n",
    "\n",
    "* Max_Depth: This determines the maximum depth of the tree. we use a depth of two to make our decision tree, This will often result in over fitted decision trees. The depth parameter is one of the ways in which we can regularize the tree, or limit the way it grows to prevent over-fitting. The tree perfectly fits the training data and fails to generalize on testing data.\n",
    "\n",
    "* Min_Samples_split: ideal range is 1 to 40.min_samples_split specifies the minimum number of samples required to split an internal node, while min_samples_Split specifies the minimum number of samples required to be at a leaf node.\n",
    "\n",
    "* Min_Samples_Leaf: The minimum number of samples required to be at a leaf node. Similiar to min sample split this describes the minimum number of samples at the leaf. the base of tree odeal range is 1 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402ee5d-8e5d-45da-8d9c-46e193d7ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For demonstration, I'm creating a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5, np.nan, 7, 8, 9, 10],\n",
    "    'feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "    'target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check for NaN values in y_train\n",
    "print(\"Checking for NaN values in y_train...\")\n",
    "if pd.isnull(y_train).any():\n",
    "    print(\"NaN values found in y_train. Handling NaNs...\")\n",
    "    y_train = y_train.fillna(y_train.mode()[0])  # Fill NaNs with the mode or another strategy\n",
    "\n",
    "# Check for NaN values in x_train\n",
    "print(\"Checking for NaN values in x_train...\")\n",
    "if x_train.isnull().values.any():\n",
    "    print(\"NaN values found in x_train. Handling NaNs...\")\n",
    "    x_train = x_train.fillna(x_train.mean())  # Fill NaNs with column means or another strategy\n",
    "\n",
    "# Check for NaN values in x_test\n",
    "print(\"Checking for NaN values in x_test...\")\n",
    "if x_test.isnull().values.any():\n",
    "    print(\"NaN values found in x_test. Handling NaNs...\")\n",
    "    x_test = x_test.fillna(x_test.mean())  # Fill NaNs with column means or another strategy\n",
    "\n",
    "# Initialize and train the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=1, splitter='random')\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_hat = dt.predict(x_test)\n",
    "print(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e42e5-572b-48b6-a5c1-56e27e02c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5, np.nan, 7, 8, 9, 10],\n",
    "    'feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "    'target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check for NaN values in y_train\n",
    "print(\"Checking for NaN values in y_train...\")\n",
    "if pd.isnull(y_train).any():\n",
    "    print(\"NaN values found in y_train. Handling NaNs...\")\n",
    "    y_train = y_train.fillna(y_train.mode()[0])  # Fill NaNs with the mode or another strategy\n",
    "\n",
    "# Check for NaN values in x_train\n",
    "print(\"Checking for NaN values in x_train...\")\n",
    "if x_train.isnull().values.any():\n",
    "    print(\"NaN values found in x_train. Handling NaNs...\")\n",
    "    x_train = x_train.fillna(x_train.mean())  # Fill NaNs with column means or another strategy\n",
    "\n",
    "# Check for NaN values in x_test\n",
    "print(\"Checking for NaN values in x_test...\")\n",
    "if x_test.isnull().values.any():\n",
    "    print(\"NaN values found in x_test. Handling NaNs...\")\n",
    "    x_test = x_test.fillna(x_test.mean())  # Fill NaNs with column means or another strategy\n",
    "\n",
    "# Initialize and train the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=1, splitter='random')\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_predict = dt.predict(x_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_predict = dt.predict(x_test)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee384fd-49b3-4174-b092-ea68a2fb7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5, np.nan, 7, 8, 9, 10],\n",
    "    'feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "    'target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check for NaN values in y_train\n",
    "print(\"Checking for NaN values in y_train...\")\n",
    "if pd.isnull(y_train).any():\n",
    "    print(\"NaN values found in y_train. Handling NaNs...\")\n",
    "    y_train = y_train.fillna(y_train.mode()[0])  # Fill NaNs with the mode or another strategy\n",
    "\n",
    "# Check for NaN values in x_train\n",
    "print(\"Checking for NaN values in x_train...\")\n",
    "if x_train.isnull().values.any():\n",
    "    print(\"NaN values found in x_train. Handling NaNs...\")\n",
    "    x_train = x_train.fillna(x_train.mean())  # Fill NaNs with column means or another strategy\n",
    "\n",
    "# Check for NaN values in x_test\n",
    "print(\"Checking for NaN values in x_test...\")\n",
    "if x_test.isnull().values.any():\n",
    "    print(\"NaN values found in x_test. Handling NaNs...\")\n",
    "    x_test = x_test.fillna(x_test.mean())  # Fill NaNs with column means or another strategy\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "params = {\n",
    "    \"criterion\": (\"gini\", \"entropy\"),\n",
    "    \"splitter\": (\"best\", \"random\"),\n",
    "    \"max_depth\": list(range(1, 20)),\n",
    "    \"min_samples_split\": list(range(2, 20)),\n",
    "    \"min_samples_leaf\": list(range(1, 20)),\n",
    "}\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=3)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"f1\", n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "tree_cv.fit(x_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Initialize and train the DecisionTreeClassifier with the best parameters\n",
    "dt = DecisionTreeClassifier(**best_params)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_predict = dt.predict(x_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_predict = dt.predict(x_test)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Classification Report for Training Set:\")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_report(y_test, y_test_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a6d1d-6a0e-4353-9e00-08133b6bbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebd35e-b8c9-41e3-8978-bb1b861f6dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276c88e-2a16-4f1c-a1a9-899487c8383b",
   "metadata": {},
   "source": [
    " # RandomForest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ef4c5-bac3-42e5-ba44-4f55bfe8b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_clf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae535e1-0a63-4aa4-b57f-742f9a7adbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d42a0d-89c1-4242-9edd-9c51a76713a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming X and y are your original data\n",
    "smote = SMOTE(random_state=42)\n",
    "x_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sm, y_sm, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the classifier\n",
    "y_p = rf_clf.predict(x_test)\n",
    "\n",
    "# Compute the F1 score\n",
    "f1 = f1_score(y_test, y_p, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ad396-62dc-4e01-b0b3-50aeab862648",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=rf_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaadb69-05a4-4b53-abfd-cb7ce88b5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe945aa7-8646-491e-8f7f-cfd565b45b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the classifier\n",
    "y_predict = rf_clf.predict(x_test)\n",
    "\n",
    "# Compute the F1 score\n",
    "f_score = f1_score(y_test, y_predict, average='weighted')\n",
    "print(f\"F1 Score: {f_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a558d9-6c04-4795-b209-e3fce88fe5b3",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "* n_estimators=number of trees in the foreset.\n",
    "* max_features= These are the maximum number of features Random forest is allowed to try in individual tree. There are multiple options available in python to assign maximum features.\n",
    "* max_depth= The depth of each tree in the forest. The deeper the tree are more splits it has and it captires more information about the data.\n",
    "* min_samples_split= The minimum number of samples required to split an internal node. This can vary between considering at least one sample at each node to considering all of the samples at each node.\n",
    "* min_samples_leaf=minimum number of data points allowed in a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104d6a6-2a8f-4d0e-940b-d1deb3a9f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "rf_clf1 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_cv = RandomizedSearchCV(estimator=rf_clf1, scoring='f1',param_distributions=random_grid, n_iter=100, cv=3,\n",
    "                           verbose=2, random_state=42, n_jobs=1)\n",
    "rf_cv.fit(x_train, y_train)\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1e3d3-41fe-46c2-b8fd-cada229ce9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_clf2 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_clf2.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the classifier\n",
    "y_predict = rf_clf2.predict(x_test)\n",
    "\n",
    "# Compute the F1 score with 'weighted' average\n",
    "f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0deb59-aaed-4504-ab95-c614423c4423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
